# -*- coding: utf-8 -*-
"""newheartdisease.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lRArHa8Ebmb8BUxoOXc9zVWN00bEHE7P
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
from matplotlib import rcParams
from matplotlib.cm import rainbow
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')

heart_data = pd.read_csv('heart-disease (1).csv')

heart_data.head()

heart_data.shape

heart_data.info()

heart_data.isnull().sum()

heart_data.describe()

missing_data = heart_data.isnull().sum()
total_percentage = (missing_data.sum()/heart_data.shape[0])*100
print(f'Total percentage of  missing data is{round(total_percentage,2)}%')
duplicate=heart_data[heart_data.duplicated()]
print("Duplicate rows:")
duplicate
heart_data=heart_data.drop_duplicates()

heart_data['target'].value_counts()

x=heart_data.drop(columns='target',axis=1)
y=heart_data['target']

print(x)

print(y)

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,stratify=y,random_state=2)

print(x.shape,x_train.shape,x_test.shape)

model=LogisticRegression()

model.fit(x_train,y_train)

x_train_prediction=model.predict(x_train)
training_data_accuracy=accuracy_score(x_train_prediction,y_train)

print('accuracy on training data:', training_data_accuracy)

x_test_prediction=model.predict(x_test)
test_data_accuracy=accuracy_score(x_test_prediction,y_test)

print('accuracy on test data:', test_data_accuracy)

input_data= (41,0,1,130,204,0,0,172,0,1.4,2,0,2)

input_data_as_numpy_array=np.asarray(input_data)

input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

"""#so if the value is 1 then the patient has heart disease
#and if thr valur is 0 then the patient has no heart disease
"""

if prediction[0]==0:
    print('the person does not have heart disease')
else:
    print('the person has heart disease')

heart_data.corr()

knn_scores=[]
for k in range(2,21):
    knn_classifier=KNeighborsClassifier(n_neighbors=k)
    knn_classifier.fit(x_train.values,y_train.values)
    knn_score=round(knn_classifier.score(x_test.values,y_test.values),2)
    knn_scores.append(knn_score)
knn_classifier = KNeighborsClassifier(n_neighbors=5)
knn_classifier.fit(x_train,y_train)
knn_score=knn_classifier.predict(x_test)
print(classification_report(y_test,knn_score))

plt.plot([k for k in range (2,21)], knn_scores,color ='red')
for i in range(2,21):
    plt.text(i,knn_scores[i-2],(i,knn_scores[i-2]))
plt.xticks([i for i in range(2,21)])
plt.xlabel('Number of Neighbors (K)')
plt.ylabel('Scores')
plt.title('KNN Scores for different K neighbouras')

from sklearn.metrics import accuracy_score

svc_scores=[]
kernels = ['linear','poly','rbf','sigmoid']
for i in range(len(kernels)):
    svc_classifier=SVC(kernel=kernels[1])
    svc_classifier.fit(x_train.values,y_train.values)
    svc_scores.append(round(svc_classifier.score(x_test.values,y_test.values),2))


svc_classifier=SVC(kernel=kernels[1])
svc_classifier.fit(x_train.values,y_train.values)
svc_prediction_results=svc_classifier.predict(x_test.values)
print(accuracy_score(y_test.values,svc_prediction_results))

colors=rainbow(np.linspace(0,1,len(kernels)))
plt.bar(kernels,svc_scores,color=colors)
for i in range(len(kernels)):
    plt.text(i,svc_scores[i],svc_scores[i])
    plt.xlabel('Kernels')
    plt.ylabel('Scores')
    plt.title('SVM scores activation function wise..')

dt_scores=[]
for i in range(1,len(x.columns)+1):
    dt_classifier=DecisionTreeClassifier(max_features=i,random_state = 0)
    dt_classifier.fit(x_train.values,y_train.values)
    dt_scores.append(round(dt_classifier.score(x_test.values,y_test.values),2))

print("Done")

print(dt_scores)

dt_classifier=DecisionTreeClassifier(max_features=13,random_state=0)
dt_classifier.fit(x_train.values,y_train.values)

plt.plot([i for i in range(1,len(x.columns)+1)],dt_scores,color='green')
for i in range(1,len(x.columns)+1):
    plt.text(i,dt_scores[i-1],dt_scores[i-1])

plt.xlabel('Max features')
plt.ylabel('Scores')
plt.title('Decision Tree Classifier scores for different number of maximum features')

rf_scores =[]
estimators =[10,20,100,200,500]
for i in estimators:
    rf_classifier=RandomForestClassifier(n_estimators=i,random_state=0)
    rf_classifier.fit(x_train.values,y_train.values)
    rf_scores.append(round(rf_classifier.score(x_test.values,y_test.values),2))

colors = rainbow(np.linspace(0,1,len(estimators)))
plt.bar([i in range(len(estimators))],rf_scores,color=colors, width=0.8)
for i in range(len(estimators)):
    plt.text(i,rf_scores[i],rf_scores[i])
plt.xticks([i for i in range(len(estimators))],estimators)
plt.xlabel('Number of Estimators')
plt.ylabel('Scores')
plt.title('Random Forest Classifier scores for different number of estimators')

Logistic_model = LogisticRegression()
Logistic_model.fit(x_train.values,y_train.values)
Logistic_model_prediction= Logistic_model.predict(x_test.values)
print(accuracy_score(y_test.values,Logistic_model_prediction))
print(classification_report(y_test.values,Logistic_model_prediction))

rf_model = RandomForestClassifier().fit(x_train,y_train)
logistic_model = LogisticRegression(max_iter=1000).fit(x_train,y_train)
dt_classifier = DecisionTreeClassifier().fit(x_train,y_train)
svc_classifier = SVC().fit(x_train,y_train)
knn_classifier = KNeighborsClassifier().fit(x_train,y_train)

import pickle
all_models = [rf_model, Logistic_model, dt_classifier, svc_classifier, knn_classifier]

with open('all_models.pkl', 'wb') as file:
    pickle.dump(all_models, file)
print("Done")

open_file =open("all_models.pkl","rb")
loaded_list=pickle.load(open_file)
print(loaded_list)
open_file.close()
print("done")